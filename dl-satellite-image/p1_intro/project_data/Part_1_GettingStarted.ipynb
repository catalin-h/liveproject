{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">Deep Learning </span> for Satellite Image Classification</span> (Manning Publications)<br/>by <em>Daniel Buscombe</em></strong><br/><br/>\n",
    "        <strong>> Chapter 1: Getting Started </strong><br/>\n",
    "    </p>           \n",
    "        \n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">What you will learn in this Part.</strong>  \n",
    "    <br/>In this first part we will refresh our jupyter, keras, Tensorflow 2, and git skills. These are a necessary part of your workflow and a standard collection of tools used in both industry and academia. Optionally, we will explore how to use the Sentinel API to download, display and save Sentinel-2 imagery.\n",
    "    \n",
    "   There may be places in this notebook where the code gets a difficult to understand. I encourage you not to get too bogged down in the details just yet; you will see many of these same functions again and each time I may explain a different aspect of them, and your understanding will improve as you progress through the project. Many of the details of the code are unimportant, at least initially, but are necessary to create functional example workflows that are relevant to later Parts \n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Introduction to<br/> Jupyter notebooks</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "<a href=\"https://jupyter.org/\">Jupyter</a> notebooks are a way to share executable code that can be run through a web browser. \n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "A notebook kernel is a computational engine that executes the code contained in a notebook. The ipython kernel executes python code. Kernels for many other languages also exist.\n",
    "</p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use question mark in order to get help. To execute cell you have to press Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to see the 'full' help menu, which is a lot of output\n",
    "#?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To execute the code in a particular cell, click on the cell and hit shift-enter.\n",
    "* Before you execute the code in an arbitrary cell it is good to run all the code once so that all imports and variables are initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('I love Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5]\n",
    "plt.plot(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question mark after a function will open pager with documentation. Double question mark will show you source code of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to see the 'full' help menu, which is a lot of output\n",
    "#plt.plot??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting text\n",
    "\n",
    "Double click on this cell to reveal the unformatted text which can then be re-executed, either from the buttons provided or by holding down shift while you press enter\n",
    "\n",
    "As you can see below, formatting text characters apply to markdown cells\n",
    "\n",
    "Emphasis, aka italics, with *asterisks* or _underscores_.\n",
    "\n",
    "Strong emphasis, aka bold, with **asterisks** or __underscores__.\n",
    "\n",
    "Combined emphasis with **asterisks and _underscores_**.\n",
    "\n",
    "Strikethrough uses two tildes. ~~Scratch this.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I'm an inline-style link](https://www.google.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write equations inline: $e = mc^2$, $e^{i\\pi}+1=0$\n",
    "\n",
    "or in display format:\n",
    "\n",
    "$$ e^x = \\sum_{i=0}^{\\infty}\\frac{1}{i!}x^i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='http://python.org/images/python-logo.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('F4rFuIb1Ie4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how long it take to run a command with %timeit magic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 12 list(range(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all interactive variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get information about all magic functions type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if you are interested in all the magic commands, \n",
    "## but it isn't necessary to read it to execute the rest of the notebook\n",
    "#%magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can navigate and list file contents in python using the ```os``` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of different ways of running a python script and passing it variables. To demonstrate this, let's first make a simple script that accepts 2 variables and prints them to screen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 50\n",
    "var2 = 'jupyter_is_cool'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```writefile``` is a so-called [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile test_script.py\n",
    "import sys\n",
    "script, var1, var2 = sys.argv\n",
    "print(\"Script name:\", script)\n",
    "print(\"First variable:\", var1)\n",
    "print(\"Second variable:\", var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the script using the ```run``` jupyter magic command. Variables are passed to the script using a $ symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./test_script.py $var1 $var2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or using the bang operator. This is the convention we'll adopt in this clinic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python test_script.py $var1 $var2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File management and resources on linux\n",
    "\n",
    "(these commands below only work in the cloud environment, unless you are in an environment supporting bash. Uncomment to run)\n",
    "\n",
    "How much memory do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /proc/meminfo | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /proc/cpuinfo | grep processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! df -h | grep \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Getting started with<br/> Tensorflow 2 and Keras</h1>  \n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "    <strong style=\"color: #182AEB;\">Intro.</strong> \n",
    "TensorFlow is a way of representing computation without actually performing it until asked. In this sense, it is a form of lazy computing, and it allows for some great improvements to the running of code:\n",
    "<ul>\n",
    "  <li>Faster computation of complex variables</li>\n",
    "  <li>Distributed computation across multiple systems, including GPUs.</li>\n",
    "  <li>Reduced redundency in some computations</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "TensorFlow allows you to create dataflow graphs. These are structures that describe how data moves through a graph, or a series of processing nodes. Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor. Keras is a set of layers that describes how to build neural networks using a clear standard. The Sequential API defines a Neural Network as a stack of layers. It very easy to define a model and to add new layers</p>\n",
    "\n",
    "<p style=\"border-left: 15px solid #4E9317; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #4E9317;\">More Resources.</strong> \n",
    "<ul>\n",
    "  <li><a href=\"https://www.tensorflow.org/tutorials\">Getting Started with Tensorflow</a></li>    \n",
    "  <li><a href=\"https://github.com/sarangzambare/segmentation\">Segmentation of cells using CNNs and TF-2</a></li>\n",
    "  <li><a href=\"https://github.com/tensorflow/models/tree/master/research/deeplab\">Segmentation Segmentation using DeepLab</a></li>\n",
    "</ul></p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to import the ```tensorflow``` module and print the version number. At the time of writing, the version number is ```2.0.0```. Be aware that it is possible this code could break with other (later/earlier) versions of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test to see if a GPU is available like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras\n",
    "\n",
    "A good way to get oriented with keras is to read the [summary documentation](https://keras.io/), but note that in this project you are recommended to use the version of keras within tensorflow, so the [tf.keras documentation](https://www.tensorflow.org/guide/keras) is also very relevant. Also, [this blog post](https://towardsdatascience.com/tensorflow-is-in-a-relationship-with-keras-introducing-tf-2-0-dcf1228f73ae) is worth a read, as is [this other blog post](https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two ways to make a model\n",
    "\n",
    "We're going to familiarize ourselves with tensorflow and keras using a relevant example, involving image classification. Instead of our project task involving semantic segmentation (classification of every pixel), computer scientists tend to refer to classification of whole images as 'image classification'.\n",
    "\n",
    "```keras``` is accessed as ```tf.keras``` and its layers can be imported separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow keras layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we have imported 2 different types of layers (`Dense`, `Dropout`), and `Flatten` that isn't technically a layer but is classified as one because it transforms a layer's dimensions (specifically, it turns a 2D matrix into a 1D vector). We will encounter and discuss further the various layers in more depth in subsequent Parts, but `Dense` is a densely connected layer where each neuron of the previous layer connects to each neuron in the previous layer. `Dropout` is one of several strategies for preventing model overfitting. It randomly drops a certain proportion of neurons, to prevent the model 'memorizing' the data and promote model generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a simple neural network model with one hidden layer that receives a 28 x 28 pixel image, and outputs one of 10 values. It has one hidden layer with 128 neurons and a rectified linear unit (```relu```) activation function. Between the hidden layer and output (classifying) layer there is a dropout layer where 20 % of neurons are randomly discarded. Softmax is an activation function. See [here](https://towardsdatascience.com/softmax-function-simplified-714068bf8156) for a good explanation. See [here](https://keras.io/activations/) for alternatives. It might be a good idea to play with different activation functions to explore their utility and effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we introduce the `Sequential` model. You should take some time to explore is numerous useful properties, such as \n",
    "\n",
    "1. `.summary()`, which shows the model architecture\n",
    "\n",
    "2. `.layers`, which lists the layers of the model and their shapes\n",
    "\n",
    "3. `.save()` saves the model in its current state of training, so you can keep a record of the state of the model at various points through training. Models can be recovered from a file using `tensorflow.keras.models.load_model()`\n",
    "\n",
    "4. `.save_weights()` saves only the weights of the model to a file\n",
    "\n",
    "5. `.inputs` and `.outputs` provide access to model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the same as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify by comparing the two model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our model to classify imagery. Load the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), split into test and training sets, and convert the samples from integers to floating-point numbers.\n",
    "\n",
    "The imagery data contained in the variables `x_test` and `x_train` are divided by 255.0 to normalize their values, such that all pixels have values that vary between 0 and 1, instead of 0 and 255 which is the the range of values for a standard 8-bit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# check some statistics\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = x_train.shape[1:3]\n",
    "print(\"# of train examples:\", x_train.shape[0])\n",
    "print(\"# of test examples:\", x_test.shape[0])\n",
    "print(\"Image shape:\", x_train[0].shape)\n",
    "print(\"Pixel value interval:\", np.min(x_train), np.max(x_train))\n",
    "print(\"Train shape:\",x_train.shape)\n",
    "print(\"Test shape:\",x_test.shape)\n",
    "print(\"Image height:\",IMAGE_HEIGHT)\n",
    "print(\"Image width:\",IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at some examples. Please remember that code such as this is provided as a succinct example workflow, but it is possible to develop similar 'solutions' on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# visualize some of the examples\n",
    "fig, axs = plt.subplots(nrows=3, ncols=6, constrained_layout=False, figsize=(12,4))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_train[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a tool for visualizing model training, such as how the loss function decreased, or accuracy increased, as a function of training epoch. Its use is often an essential part of optimizing model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "# create the tensorboard callback\n",
    "tensorboard = TensorBoard(log_dir='logs', histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.compile()` is a required step before model training. The following must be specified:\n",
    "\n",
    "1. `optimizer` that performs the gradient descent (numerical solver)\n",
    "\n",
    "2. `loss` that is the metric to be optimized. Below we choose `sparse_categorical_crossentropy` because we have a categorical problem (hence `categorical_crossentropy`) that is not [one-hot-encoded](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) (hence `sparse`)\n",
    "\n",
    "3. `metrics`, which are additional metrics to evaluate during training  but, unlike loss, are not used in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard for visualizing model training. You should see graphs `epoch_accuracy` and `epoch_loss` that show accuracy and loss function value, respectively, as a function of training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch TensorBoard from Jupyter\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in ```evaluate``` function to see overall classification loss (first number) and accuracy (second number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Confusion Matrix\n",
    "A ‘confusion matrix’, which is the matrix of normalized correspondences between true and estimated labels, is a convenient way to visualize model skill. \n",
    "\n",
    "A perfect correspondence between true and estimated labels is scored 1.0 along the diagonal elements of the matrix.\n",
    "\n",
    "Misclassiﬁcations are readily identiﬁed as off-diagonal elements. Systematic misclassiﬁcations are recognized as off-diagonal elements with large magnitudes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is long and might be difficult to follow in parts. This is a good time to remind you that that's ok; you will see this function again, and it isn't crucial to any workflow you will develop. It serves only to exemplify and guide, and many the details of many of the long functions such as these are largely unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in ```predict``` function to create a vector of predicted classes for each input in the ```x_test``` set. These values are one-hot encoded, which means we recover the most likely class using the ```argmax``` function (i.e. the location in the vector, ```predictions```, of the maximum value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model using the test data\n",
    "predictions = model.predict(x_test)\n",
    "predictions = tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the confusion matrix\n",
    "classes=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "plot_confusion_matrix(y_test, predictions, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above demonstration shows that for relatively simple classification tasks (i.e. recognizing handwritten digits) doesn't necessarily require deep learning. Our network was small, consisting of only one hidden layer. In the next task we will be using much bigger, more powerful networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">Deliverable</strong>  \n",
    "    <br/>The deliverable for Part 1 is a jupyter notebook showing an example image(s) of a satellite dataset read in using rasterio, and demonstration of a function that carries out a manipulation of that image using keras and Tensorflow 2.0. That manipulation could be anything that alters the image, such as its size, geometry (shape), pixel intensities, or spatial projection. This will mostly test your understanding of keras syntax, which is an essential component of the remaining Parts. You may find the <a href=\"https://www.tensorflow.org/api_docs/python/tf/image\">tensorflow-image</a> library helpful.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Going further: <br/> Introduction to satellite imagery</h1>  \n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "    <strong style=\"color: #182AEB;\">Intro.</strong>\n",
    "    The <a href=\"https://sentinels.copernicus.eu/\">Sentinel satellites</a> are part of Europe’s <a href=\"http://copernicus.eu/\">Copernicus </a> programme (formerly known as Global Monitoring for Environment and Security (GMES)). The overall mission is composed of five constellations of satellites. The Sentinel-2 mission consists of two satellites with a multi-spectral instrument for monitoring agriculture, vegetation and forests, land cover change, coastal zones, inland water monitoring, glaciers, ice extent and snow cover.\n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "    A comprehensive introduction to the mission and its data can be found <a href=\"https://eox.at/2015/12/understanding-sentinel-2-satellite-data/\"> here</a>. Your starting point for all data services is <a href=\"https://www.sentinel-hub.com/sentinel-2\">Sentinel Hub </a></p>\n",
    "\n",
    "<p style=\"border-left: 15px solid #4E9317; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #4E9317;\">More Resources.</strong> \n",
    "<ul>\n",
    "  <li><a href=\"https://krstn.eu/download-Sentinel-2-images/\">Another guide to using sentinselsat</a></li>    \n",
    "  <li><a href=\"https://automating-gis-processes.github.io/CSC18/lessons/L6/raster-mosaic.html\">Using rasterio</a></li>\n",
    "</ul>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing a satellite image using rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download a sample Sentinel-2 JP2 (JPEG2000) file from google drive\n",
    "\n",
    "The details of this function are unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1o76QoBtn6ExxO8KgcCqdOiun_KsWoMJl'\n",
    "destination = 'example_TCI_10m.jp2'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read first band of the jp2 file into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('example_TCI_10m.jp2', driver='JP2OpenJPEG') as dataset:\n",
    "    array = dataset.read(1)\n",
    "    print(dataset.profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 3 means there are three bands in the raster:\n",
    "\n",
    "* Band 1 - the blue band\n",
    "* Band 2 - the green band\n",
    "* Band 3 - the red band\n",
    "\n",
    "A few more jp2 images can be downloaded using the following file id: 1o76QoBtn6ExxO8KgcCqdOiun_KsWoMJl. This is a zipped folder 120 MB in size containing several images of the area around Lake Poopó, Bolivia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing a satellite image to geotiff using rasterio\n",
    "\n",
    "The following function takes a JP2 image, an output file name (with tiff extension) and a single band number (1, 2, or 3) and writes the raster to the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(input, output, band):\n",
    "    with rasterio.open(input) as src_dataset:\n",
    "        with rasterio.open('example_TCI_10m.jp2', driver='JP2OpenJPEG') as dataset:\n",
    "            array = dataset.read(band)\n",
    "        # Get a copy of the source dataset's profile. Thus our\n",
    "        # destination dataset will have the same dimensions,\n",
    "        # number of bands, data type, and georeferencing as the\n",
    "        # source dataset.\n",
    "        kwds = src_dataset.profile\n",
    "\n",
    "        # Change the format driver for the destination dataset to\n",
    "        # 'GTiff', short for GeoTIFF.\n",
    "        kwds['driver'] = 'GTiff'\n",
    "\n",
    "        # Add GeoTIFF-specific keyword arguments.\n",
    "        kwds['tiled'] = True\n",
    "        kwds['blockxsize'] = 256\n",
    "        kwds['blockysize'] = 256\n",
    "        kwds['photometric'] = 'YCbCr'\n",
    "        kwds['compress'] = 'JPEG'\n",
    "\n",
    "        with rasterio.open(output, 'w', **kwds) as dst_dataset:\n",
    "            # Write data to the destination dataset.\n",
    "            dst_dataset.write(array.astype(rasterio.uint8), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of files we will create, each with a 1-band raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['r1.tif', 'r2.tif', 'r3.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use list comprehension to call the ```write_image``` function for all 3 bands in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[write_image('example_TCI_10m.jp2',f, band) for f,band in zip(file_list, [1,2,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next bit of code gets the meta data from the first file (that is the same as the remaining two files), and writes a merged 3-band raster in geoTIFF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata of first file\n",
    "with rasterio.open(file_list[0]) as src0:\n",
    "    meta = src0.meta\n",
    "\n",
    "# Update meta to reflect the number of layers\n",
    "meta.update(count = len(file_list))\n",
    "\n",
    "# Read each layer and write it to stack\n",
    "with rasterio.open('stack.tif', 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(file_list, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now done with the three intermediate files, so we can delete them to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[os.remove(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the new meta data that shows the Coordinate Reference System or CRS. The EPSG code is 32719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image spatial projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to reproject our raster so it is in a different spatial projection. This involves specifying a new CRS (this time we use EPSG code 4326)\n",
    "\n",
    "Example modified from https://rasterio.readthedocs.io/en/stable/topics/reproject.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import some utility functions from rasterio that will create and apply the transformation. Again we use a nested 'with statement' to first read in the raster to be projected (```stack.tif```) and then write out the reprojected raster (```reprojected_stack.tif```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "dst_crs = 'EPSG:4326'\n",
    "\n",
    "# note there is a nested 'with statement' here\n",
    "# the first 'with' command opens the image as src\n",
    "with rasterio.open('stack.tif') as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "# the second 'with' statement opens an image for writing\n",
    "    with rasterio.open('reprojected_stack.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
